# EX-02-Cross-Platform-Prompting-Evaluating-Diverse-Techniques-in-AI-Powered-Text-Summarization

## AIM
To evaluate and compare the effectiveness of prompting techniques (zero-shot, few-shot, chain-of-thought, role-based) across different AI platforms (e.g., ChatGPT, Gemini, Claude, Copilot) in a specific task: text summarization.

## Scenario:
You are part of a content curation team for an educational platform that delivers quick summaries of research papers to undergraduate students. Your task is to summarize a 500-word technical article on "The Basics of Blockchain Technology" using multiple AI platforms and prompting strategies.

Your goal is to determine which combination of prompting technique + platform provides the best summary in terms of:

Accuracy

Coherence

Simplicity

Speed

User experience

## Algorithm
The experiment evaluates leading AI platforms—ChatGPT, Gemini, Perplexity, Google AI, and Meta—using the same prompt and identical conditions. Outputs are scored for accuracy, clarity, depth, relevance, and response time, and the performance data is summarized in a comparison table to identify the most effective platform for technical summarization or Q&A.

### Comparative Results Table
Platform	Accuracy	Clarity	Depth	Relevance	Response Time
ChatGPT	High	High	High	High	Fast
Gemini	Medium	High	Medium	Medium	Fast
Perplexity	High	Moderate	Moderate	High	Fastest
Google AI	Medium	High	Medium	Medium	Fast
Meta	Medium	Medium	Medium	Medium	Fast
Analysis of Findings
ChatGPT excels in technical summarization, delivering the most consistent results for accuracy, clarity, depth, and relevance.

Gemini provides clear and well-formatted answers, but may lack technical detail or strict adherence to prompt constraints.

Perplexity is outstanding in factual search and citation, provides immediate results, but sacrifices conversational depth and creative reasoning.

Google AI (Gemini or Bard lineage) benefits from Google's ecosystem integration, handling multimodal and long-context queries well but sometimes leans towards generic summaries.

Meta ranks average across criteria, occasionally lagging in technical nuance and output depth.


## Result
ChatGPT leads in overall effectiveness for technical summarization and Q&A, driven by deep reasoning and fulfilling detailed prompt requirements. Perplexity is preferred for fact-checking and speed. Gemini and Google AI are best for multimodal, context-rich tasks, while Meta offers baseline utility without specialization. These findings enable practical platform selection based on specific task needs—whether accurate summarization, fast fact retrieval, or integration with workflow tools

